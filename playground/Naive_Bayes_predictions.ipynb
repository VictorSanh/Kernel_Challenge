{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../')\n",
    "\n",
    "from data_handler import *\n",
    "\n",
    "import numpy as np\n",
    "from textwrap import wrap\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Consecutive substrings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def learn_probs(data_train, substring_length):\n",
    "#     '''Learn the probabilities by counting \n",
    "#     the number of time a substring was implied in a binding sequence'''\n",
    "\n",
    "#     counts = {}\n",
    "#     for _, row in data_train.iterrows():\n",
    "#         sequence = row['Sequence']\n",
    "#         binding = row['Bound']\n",
    "#         substrings = wrap(sequence, substring_length)\n",
    "#         for substr in substrings:\n",
    "#             if substr in counts.keys():\n",
    "#                 counts[substr]['count'] = counts[substr]['count'] + 1\n",
    "#                 counts[substr]['binding'] = counts[substr]['binding'] + int(binding)\n",
    "#             else:\n",
    "#                 counts[substr] = {'count': 1, 'binding': int(binding)}\n",
    "\n",
    "#     probs = {}\n",
    "#     for substr in counts.keys():\n",
    "#         probs[substr] = counts[substr]['binding']/counts[substr]['count']\n",
    "        \n",
    "#     return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for sequence in data_test['Sequence']:\n",
    "#     for t in wrap(sequence, substring_length):\n",
    "#         if t not in probs.keys(): print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def compute_binding_prob(sequence, prob_dict, substring_length):\n",
    "#     proba = 1\n",
    "#     for substring in wrap(sequence, substring_length):\n",
    "#         if substring in prob_dict.keys():\n",
    "#             proba *= prob_dict[substring]\n",
    "#         else:\n",
    "#             print('not in training')\n",
    "#             proba *= 0.5\n",
    "#     return 1 - proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Loading training data\n",
    "# tr0 = load_data(0, 'tr')\n",
    "# tr1 = load_data(1, 'tr')\n",
    "# tr2 = load_data(2, 'tr')\n",
    "\n",
    "# ## Loading test data\n",
    "# te0 = load_data(0, 'te')\n",
    "# te1 = load_data(1, 'te')\n",
    "# te2 = load_data(2, 'te')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Set 0**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for substring_length in [3,4,5,6]:\n",
    "\n",
    "#     probs = learn_probs(tr0, substring_length)\n",
    "#     sequence_prob = []\n",
    "#     for _, row in tr0.iterrows():\n",
    "#         seq = row['Sequence']\n",
    "#         binding = row['Bound']\n",
    "#         sequence_prob.append(compute_binding_prob(seq, probs, substring_length))\n",
    "\n",
    "#     predictions = np.array(sequence_prob)>np.mean(sequence_prob)\n",
    "#     acc = 100*np.mean(predictions == tr0['Bound'])\n",
    "#     print('Substring Length: {} - Accuracy: {:.2f}%'.format(substring_length, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for substring_length in [3,4,5,6]:\n",
    "\n",
    "#     probs = learn_probs(tr1, substring_length)\n",
    "\n",
    "#     sequence_prob = []\n",
    "#     for _, row in tr1.iterrows():\n",
    "#         seq = row['Sequence']\n",
    "#         binding = row['Bound']\n",
    "#         sequence_prob.append(compute_binding_prob(seq, probs, substring_length))\n",
    "\n",
    "#     predictions = np.array(sequence_prob)>np.mean(sequence_prob)\n",
    "#     acc = 100*np.mean(predictions == tr1['Bound'])\n",
    "#     print('Substring Length: {} - Accuracy: {:.2f}%'.format(substring_length, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for substring_length in [3,4,5,6]:\n",
    "\n",
    "#     probs = learn_probs(tr2, substring_length)\n",
    "\n",
    "#     sequence_prob = []\n",
    "#     for _, row in tr2.iterrows():\n",
    "#         seq = row['Sequence']\n",
    "#         binding = row['Bound']\n",
    "#         sequence_prob.append(compute_binding_prob(seq, probs, substring_length))\n",
    "\n",
    "#     predictions = np.array(sequence_prob)>np.mean(sequence_prob)\n",
    "#     acc = 100*np.mean(predictions == tr2['Bound'])\n",
    "#     print('Substring Length: {} - Accuracy: {:.2f}%'.format(substring_length, acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sliding window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def learn_probs_sliding(data_train, substring_length):\n",
    "#     '''Learn the probabilities by counting \n",
    "#     the number of time a substring was implied in a binding sequence'''\n",
    "\n",
    "#     counts = {}\n",
    "#     for _, row in data_train.iterrows():\n",
    "#         sequence = row['Sequence']\n",
    "#         binding = row['Bound']\n",
    "#         for start in range(len(sequence) - substring_length + 1):\n",
    "#             end = start + substring_length\n",
    "#             substr = sequence[start:end]\n",
    "#             if substr in counts.keys():\n",
    "#                 counts[substr]['count'] = counts[substr]['count'] + 1\n",
    "#                 counts[substr]['binding'] = counts[substr]['binding'] + int(binding)\n",
    "#             else:\n",
    "#                 counts[substr] = {'count': 1, 'binding': int(binding)}\n",
    "\n",
    "#     probs = {}\n",
    "#     for substr in counts.keys():\n",
    "#         probs[substr] = counts[substr]['binding']/counts[substr]['count']\n",
    "        \n",
    "#     return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def compute_binding_prob_sliding(sequence, prob_dict, substring_length):\n",
    "#     proba = 1\n",
    "#     for start in range(len(sequence) - substring_length + 1):\n",
    "#         end = start + substring_length\n",
    "#         substring = sequence[start:end]\n",
    "#         if substring in prob_dict.keys():\n",
    "#             proba *= prob_dict[substring]\n",
    "#         else:\n",
    "#             print('not in training')\n",
    "#             proba *= 0.5\n",
    "#     return 1 - proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for substring_length in [3,4,5,6]:\n",
    "\n",
    "#     probs = learn_probs_sliding(tr0, substring_length)\n",
    "#     sequence_prob = []\n",
    "#     for _, row in tr0.iterrows():\n",
    "#         seq = row['Sequence']\n",
    "#         binding = row['Bound']\n",
    "#         sequence_prob.append(compute_binding_prob_sliding(seq, probs, substring_length))\n",
    "\n",
    "#     predictions = np.array(sequence_prob)>np.mean(sequence_prob)\n",
    "#     acc = 100*np.mean(predictions == tr0['Bound'])\n",
    "#     print('Substring Length: {} - Accuracy: {:.2f}%'.format(substring_length, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for substring_length in [3,4,5,6]:\n",
    "\n",
    "#     probs = learn_probs_sliding(tr1, substring_length)\n",
    "#     sequence_prob = []\n",
    "#     for _, row in tr0.iterrows():\n",
    "#         seq = row['Sequence']\n",
    "#         binding = row['Bound']\n",
    "#         sequence_prob.append(compute_binding_prob_sliding(seq, probs, substring_length))\n",
    "\n",
    "#     predictions = np.array(sequence_prob)>np.mean(sequence_prob)\n",
    "#     acc = 100*np.mean(predictions == tr0['Bound'])\n",
    "#     print('Substring Length: {} - Accuracy: {:.2f}%'.format(substring_length, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for substring_length in [3,4,5,6]:\n",
    "\n",
    "#     probs = learn_probs_sliding(tr2, substring_length)\n",
    "#     sequence_prob = []\n",
    "#     for _, row in tr0.iterrows():\n",
    "#         seq = row['Sequence']\n",
    "#         binding = row['Bound']\n",
    "#         sequence_prob.append(compute_binding_prob_sliding(seq, probs, substring_length))\n",
    "\n",
    "#     predictions = np.array(sequence_prob)>np.mean(sequence_prob)\n",
    "#     acc = 100*np.mean(predictions == tr0['Bound'])\n",
    "#     print('Substring Length: {} - Accuracy: {:.2f}%'.format(substring_length, acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tr0_b = tr0[tr0['Bound']==True]\n",
    "# tr0_nb = tr0[tr0['Bound']==False]\n",
    "\n",
    "# unique_b = set()\n",
    "# for _, row in tr0_b.iterrows():\n",
    "#     seq = row['Sequence']\n",
    "#     for el in wrap(seq, substring_length):\n",
    "#         unique_b.add(el)\n",
    "        \n",
    "# unique_nb = set()\n",
    "# for _, row in tr0_nb.iterrows():\n",
    "#     seq = row['Sequence']\n",
    "#     for el in wrap(seq, substring_length):\n",
    "#         unique_nb.add(el)\n",
    "        \n",
    "# unique_b == unique_nb        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loading training data\n",
    "tr0 = load_data(0, 'tr')\n",
    "tr1 = load_data(1, 'tr')\n",
    "tr2 = load_data(2, 'tr')\n",
    "\n",
    "## Loading test data\n",
    "te0 = load_data(0, 'te')\n",
    "te1 = load_data(1, 'te')\n",
    "te2 = load_data(2, 'te')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Without Sliding window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_unique_features(sequences, substring_length):\n",
    "    '''Go through the whole training set to extract the \n",
    "    unique features (substring of size substring_length).\n",
    "    No sliding window'''\n",
    "    unique_features = set()\n",
    "    for seq in sequences:\n",
    "        for substring in wrap(seq, substring_length):\n",
    "            unique_features.add(substring)\n",
    "            \n",
    "    return unique_features\n",
    "        \n",
    "\n",
    "def compute_probabilities(pd_data, substring_length, unique_features):\n",
    "    '''Compute the probabilities of observing each feature conditionned on bounding or not.'''\n",
    "    \n",
    "    pd_data['wrapped'] = pd_data.apply(lambda x: wrap(x['Sequence'], substring_length), axis = 1)\n",
    "    probs = {}\n",
    "\n",
    "    data_bounded = pd_data[pd_data['Bound']]\n",
    "    data_not_bounded = pd_data[~pd_data['Bound']]\n",
    "\n",
    "    #Compute probabilities\n",
    "    for feature in unique_features:\n",
    "        bounded_prop = data_bounded.apply(lambda x: feature in x['wrapped'], axis = 1)\n",
    "        bounded_prop = bounded_prop.astype(np.float128).mean()\n",
    "        \n",
    "        not_bounded_prop = data_not_bounded.apply(lambda x: feature in x['wrapped'], axis = 1)\n",
    "        not_bounded_prop = not_bounded_prop.astype(np.float128).mean()\n",
    "        \n",
    "        probs[feature] = {'bounded': bounded_prop, 'not_bounded': bounded_prop}\n",
    "    \n",
    "    return probs\n",
    "\n",
    "\n",
    "def pred(sequence, substring_length, probs):\n",
    "    '''Given the training (probs and unique_features), predict the class of the input sequence.\n",
    "    If True -> Bounded sequence.'''\n",
    "\n",
    "    bounded_prob_log = 0\n",
    "    not_bounded_prob_log = 0\n",
    "\n",
    "    for feature in wrap(sequence, substring_length):\n",
    "        if feature in probs.keys():\n",
    "            bounded_prob_log += np.log(probs[feature]['bounded'])\n",
    "            not_bounded_prob_log += np.log(probs[feature]['not_bounded'])\n",
    "    return (bounded_prob_log > not_bounded_prob_log) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on train set 0.5\n"
     ]
    }
   ],
   "source": [
    "data = tr0\n",
    "substring_length = 4\n",
    "\n",
    "#Training\n",
    "unique_features = extract_unique_features(data['Sequence'], substring_length)\n",
    "probabilities = compute_probabilities(data, substring_length, unique_features)\n",
    "\n",
    "#Predictions\n",
    "predictions = []\n",
    "for seq in data['Sequence']:\n",
    "    seq_pred = pred(seq, substring_length, probabilities)\n",
    "    predictions.append(seq_pred)\n",
    "    \n",
    "print('Accuracy on train set {}'.format(np.mean(predictions==data['Bound'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With sliding window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_substrings(string, substring_length):\n",
    "    return [string[x:x+substring_length] for x in range(len(string)-substring_length+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_unique_features_sliding(sequences, substring_length):\n",
    "    '''Go through the whole training set to extract the \n",
    "    unique features (substring of size substring_length).\n",
    "    With sliding window'''\n",
    "    unique_features = set()\n",
    "    for seq in sequences:\n",
    "        for substring in get_all_substrings(seq, substring_length):\n",
    "            unique_features.add(substring)\n",
    "            \n",
    "    return unique_features\n",
    "        \n",
    "\n",
    "def compute_probabilities_sliding(pd_data, substring_length, unique_features):\n",
    "    '''Compute the probabilities of observing each feature conditionned on bounding or not.'''\n",
    "    \n",
    "    pd_data['wrapped'] = pd_data.apply(lambda x: get_all_substrings(x['Sequence'], substring_length), axis = 1)\n",
    "    probs = {}\n",
    "\n",
    "    data_bounded = pd_data[pd_data['Bound']]\n",
    "    data_not_bounded = pd_data[~pd_data['Bound']]\n",
    "\n",
    "    #Compute probabilities\n",
    "    for feature in unique_features:\n",
    "        bounded_prop = data_bounded.apply(lambda x: feature in x['wrapped'], axis = 1)\n",
    "        bounded_prop = bounded_prop.astype(np.float128).mean()\n",
    "        \n",
    "        not_bounded_prop = data_not_bounded.apply(lambda x: feature in x['wrapped'], axis = 1)\n",
    "        not_bounded_prop = not_bounded_prop.astype(np.float128).mean()\n",
    "        \n",
    "        probs[feature] = {'bounded': bounded_prop, 'not_bounded': not_bounded_prop}\n",
    "    \n",
    "    return probs\n",
    "\n",
    "\n",
    "def pred_sliding(sequence, substring_length, probs):\n",
    "    '''Given the training (probs and unique_features), predict the class of the input sequence.\n",
    "    If True -> Bounded sequence.'''\n",
    "\n",
    "    bounded_prob_log = 0\n",
    "    not_bounded_prob_log = 0\n",
    "\n",
    "    for feature in get_all_substrings(sequence, substring_length):\n",
    "        if feature in probs.keys():\n",
    "            bounded_prob_log += np.log(probs[feature]['bounded'])\n",
    "            not_bounded_prob_log += np.log(probs[feature]['not_bounded'])\n",
    "    return (bounded_prob_log > not_bounded_prob_log) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dataset 0**\n",
    "* Substring_length = 3 -> Training Accuracy = 64.2%\n",
    "* Substring_length = 4 -> Training Accuracy = 74.85%\n",
    "* Substring_length = 5 -> Training Accuracy = 81.65%\n",
    "* Substring_length = 6 -> Training Accuracy = 91.2%\n",
    "* Substring_length = 7 -> Training Accuracy = 99.65%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substring Length 3 - Acc on train set 0.642\n",
      "Substring Length 4 - Acc on train set 0.7485\n",
      "Substring Length 5 - Acc on train set 0.8165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:44: RuntimeWarning: divide by zero encountered in log\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:45: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substring Length 6 - Acc on train set 0.912\n"
     ]
    }
   ],
   "source": [
    "data = tr0\n",
    "\n",
    "for substring_length in [3,4,5,6]:\n",
    "    #Training\n",
    "    unique_features = extract_unique_features_sliding(data['Sequence'], substring_length)\n",
    "    probabilities = compute_probabilities_sliding(data, substring_length, unique_features)\n",
    "    \n",
    "    #Predictions\n",
    "    predictions = []\n",
    "    for seq in data['Sequence']:\n",
    "        seq_pred = pred_sliding(seq, substring_length, probabilities)\n",
    "        predictions.append(seq_pred)\n",
    "        \n",
    "    acc = np.mean(predictions==data['Bound'])\n",
    "    print('Substring Length {} - Acc on train set {}'.format(substring_length, acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dataset 1**\n",
    "* Substring_length = 3 -> Training Accuracy = 67.5%\n",
    "* Substring_length = 4 -> Training Accuracy = 70.65%\n",
    "* Substring_length = 5 -> Training Accuracy = 74.45%\n",
    "* Substring_length = 6 -> Training Accuracy = 80.9%\n",
    "* Substring_length = 7 -> Training Accuracy = 97.0%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substring Length 3 - Acc on train set 0.675\n",
      "Substring Length 4 - Acc on train set 0.7065\n",
      "Substring Length 5 - Acc on train set 0.7445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:44: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substring Length 6 - Acc on train set 0.809\n"
     ]
    }
   ],
   "source": [
    "data = tr1\n",
    "\n",
    "for substring_length in [3,4,5,6]:\n",
    "    #Training\n",
    "    unique_features = extract_unique_features_sliding(data['Sequence'], substring_length)\n",
    "    probabilities = compute_probabilities_sliding(data, substring_length, unique_features)\n",
    "\n",
    "    #Predictions\n",
    "    predictions = []\n",
    "    for seq in data['Sequence']:\n",
    "        seq_pred = pred_sliding(seq, substring_length, probabilities)\n",
    "        predictions.append(seq_pred)\n",
    "        \n",
    "    acc = np.mean(predictions==data['Bound'])\n",
    "    print('Substring Length {} - Acc on train set {}'.format(substring_length, acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dataset 2**\n",
    "* Substring_length = 3 -> Training Accuracy = 58%\n",
    "* Substring_length = 4 -> Training Accuracy = 62.6%\n",
    "* Substring_length = 5 -> Training Accuracy = 69.65%\n",
    "* Substring_length = 6 -> Training Accuracy = 83.1%\n",
    "* Substring_length = 7 -> Training Accuracy = 98.7%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substring Length 3 - Acc on train set 0.58\n",
      "Substring Length 4 - Acc on train set 0.626\n",
      "Substring Length 5 - Acc on train set 0.6965\n",
      "Substring Length 6 - Acc on train set 0.831\n"
     ]
    }
   ],
   "source": [
    "data = tr2\n",
    "\n",
    "for substring_length in [3,4,5,6]:\n",
    "    #Training\n",
    "    unique_features = extract_unique_features_sliding(data['Sequence'], substring_length)\n",
    "    probabilities = compute_probabilities_sliding(data, substring_length, unique_features)\n",
    "\n",
    "    #Predictions\n",
    "    predictions = []\n",
    "    for seq in data['Sequence']:\n",
    "        seq_pred = pred_sliding(seq, substring_length, probabilities)\n",
    "        predictions.append(seq_pred)\n",
    "        \n",
    "    acc = np.mean(predictions==data['Bound'])\n",
    "    print('Substring Length {} - Acc on train set {}'.format(substring_length, acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:45: RuntimeWarning: divide by zero encountered in log\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:44: RuntimeWarning: divide by zero encountered in log\n"
     ]
    }
   ],
   "source": [
    "tr0 = load_data(0, 'tr')\n",
    "te0 = load_data(0, 'te')\n",
    "\n",
    "\n",
    "substring_length = 7\n",
    "unique_features = extract_unique_features_sliding(tr0['Sequence'], substring_length)\n",
    "probabilities = compute_probabilities_sliding(tr0, substring_length, unique_features)\n",
    "\n",
    "naive_bayes_te0_raw = []\n",
    "for seq in te0['Sequence']:\n",
    "    seq_pred = pred_sliding(seq, substring_length, probabilities)\n",
    "    naive_bayes_te0_raw.append(int(seq_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:44: RuntimeWarning: divide by zero encountered in log\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:45: RuntimeWarning: divide by zero encountered in log\n"
     ]
    }
   ],
   "source": [
    "tr1 = load_data(1, 'tr')\n",
    "te1 = load_data(1, 'te')\n",
    "\n",
    "\n",
    "substring_length = 7\n",
    "unique_features = extract_unique_features_sliding(tr1['Sequence'], substring_length)\n",
    "probabilities = compute_probabilities_sliding(tr1, substring_length, unique_features)\n",
    "\n",
    "naive_bayes_te1_raw = []\n",
    "for seq in te1['Sequence']:\n",
    "    seq_pred = pred_sliding(seq, substring_length, probabilities)\n",
    "    naive_bayes_te1_raw.append(int(seq_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:45: RuntimeWarning: divide by zero encountered in log\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:44: RuntimeWarning: divide by zero encountered in log\n"
     ]
    }
   ],
   "source": [
    "tr2 = load_data(2, 'tr')\n",
    "te2 = load_data(2, 'te')\n",
    "\n",
    "\n",
    "substring_length = 7\n",
    "unique_features = extract_unique_features_sliding(tr2['Sequence'], substring_length)\n",
    "probabilities = compute_probabilities_sliding(tr2, substring_length, unique_features)\n",
    "\n",
    "naive_bayes_te2_raw = []\n",
    "for seq in te2['Sequence']:\n",
    "    seq_pred = pred_sliding(seq, substring_length, probabilities)\n",
    "    naive_bayes_te2_raw.append(int(seq_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_bayes_te0_raw = pd.DataFrame(\n",
    "    data = format_preds(naive_bayes_te0_raw),\n",
    "    columns = ['Bound'])\n",
    "\n",
    "naive_bayes_te1_raw = pd.DataFrame(\n",
    "    data = format_preds(naive_bayes_te1_raw),\n",
    "    columns = ['Bound'])\n",
    "naive_bayes_te1_raw.index = naive_bayes_te1_raw.index + 1000\n",
    "\n",
    "naive_bayes_te2_raw = pd.DataFrame(\n",
    "    data = format_preds(naive_bayes_te2_raw),\n",
    "    columns = ['Bound'])\n",
    "naive_bayes_te2_raw.index = naive_bayes_te2_raw.index + 2000\n",
    "\n",
    "frames = [naive_bayes_te0_raw, naive_bayes_te1_raw, naive_bayes_te2_raw]\n",
    "naive_bayes_te = pd.concat(frames)\n",
    "naive_bayes_te.index = naive_bayes_te.index.set_names(['Id'])\n",
    "\n",
    "naive_bayes_te.to_csv('predictions/naive_bayes_7_te.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
