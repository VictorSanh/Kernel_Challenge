{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n"
     ]
    }
   ],
   "source": [
    "%reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../')\n",
    "\n",
    "from data_handler import *\n",
    "\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loading training data\n",
    "tr0 = load_data(0, 'tr')\n",
    "tr1 = load_data(1, 'tr')\n",
    "tr2 = load_data(2, 'tr')\n",
    "\n",
    "## Loading test data\n",
    "te0 = load_data(0, 'te')\n",
    "te1 = load_data(1, 'te')\n",
    "te2 = load_data(2, 'te')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vocab(alphabet, substring_length):\n",
    "    '''\n",
    "    Create all the vocabulary of all possibles words using the alphabet: all\n",
    "    combination of length substring_length. Vocabulary is of size |alphabet|^substring_length.\n",
    "    \n",
    "    Input:\n",
    "        alphabet: letters available in the alphabet\n",
    "        substring_length: lenghth of words\n",
    "        \n",
    "    Output:\n",
    "        vocab2index: dictionary associating each word in the vocab to an index (integer)\n",
    "        index2vocab: dictionary associating each index to a word in the vocab\n",
    "    '''\n",
    "    vocab = [''.join(i) for i in itertools.product(alphabet, repeat = substring_length)]\n",
    "    \n",
    "    vocab2index = {}\n",
    "    index2vocab = {}\n",
    "    for idx, v in enumerate(vocab):\n",
    "        vocab2index[v] = idx\n",
    "        index2vocab[idx] = v\n",
    "        \n",
    "    return vocab2index, index2vocab\n",
    "\n",
    "\n",
    "def is_neighbour(alpha, beta, mismatch):\n",
    "    '''\n",
    "    Check if word beta is in the neighbourhood of word alpha as defined by Leslie and al.\n",
    "    http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.86.7384&rep=rep1&type=pdf\n",
    "    \n",
    "    Input:\n",
    "        alpha: first word\n",
    "        beta: second word\n",
    "        mismatch: tolerance of mismatch\n",
    "    Output\n",
    "        Boolean: True if beta is the mismatch-neighbourhood of alpha\n",
    "    '''\n",
    "    if sum(a!=b for a, b in zip(alpha, beta)) <= mismatch:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "def compute_neighbours(vocab2index, mismatch):\n",
    "    '''\n",
    "    Compute once for all the neighbours of each word in the vocabulary.\n",
    "    \n",
    "    Input:\n",
    "        vocab2index: vocabulary\n",
    "        mismatch: tolerance of mismatch\n",
    "    Output:\n",
    "        Dictionary of neighbours for each word in the vocabulary.\n",
    "    '''\n",
    "    vocab = vocab2index.keys()\n",
    "    \n",
    "    neighbours = {}\n",
    "    for word1 in vocab:\n",
    "        neighbours[word1] = []\n",
    "        for word2 in vocab:\n",
    "            if is_neighbour(word1, word2, mismatch):\n",
    "                neighbours[word1].append(word2)\n",
    "    \n",
    "    return neighbours\n",
    "\n",
    "\n",
    "def create_mismatch_feature(sequence, substring_length, vocab2index, neighbours):\n",
    "    '''\n",
    "    Mismatch kernel feature as described by Leslie and al.\n",
    "    http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.86.7384&rep=rep1&type=pdf\n",
    "    \n",
    "    Input:\n",
    "        sequence: DNA sequence to process\n",
    "        substring_length: lenghth of vocabulary words\n",
    "        vocab2index: mapping of vocabulary word to their index\n",
    "        neighbours: neighbours for each word for each of the word in the vocabulary\n",
    "    Output:\n",
    "        Numpy array: Sequence embedding\n",
    "    '''\n",
    "    embedding = np.zeros(len(vocab2index), dtype = 'int')\n",
    "\n",
    "    for start in range(len(sequence) - substring_length + 1):\n",
    "        end = start + substring_length\n",
    "        substring = sequence[start:end]\n",
    "        for neighbour in neighbours[substring]:\n",
    "            embedding[vocab2index[neighbour]] += 1\n",
    "    \n",
    "    return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Alphabet\n",
    "alphabet = ['A', 'C', 'G', 'T']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([42, 38, 38, ..., 44, 41, 43])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "substring_length = 5\n",
    "mismatch_tol = 3\n",
    "\n",
    "vocab2index, _ = create_vocab(alphabet, substring_length)\n",
    "neighbours = compute_neighbours(vocab2index, mismatch_tol)\n",
    "\n",
    "\n",
    "#Example\n",
    "create_mismatch_feature(tr0['Sequence'][10], substring_length, vocab2index, neighbours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = tr1\n",
    "\n",
    "X = np.zeros((len(data), len(vocab2index)))\n",
    "for idx, seq in enumerate(data['Sequence']):\n",
    "    X[idx, :] = create_mismatch_feature(seq, substring_length, vocab2index, neighbours)\n",
    "Y = data['Bound']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression - l1 penalty - C: 0.001 - Mean Cross Validation Score: 63.95%\n",
      "Logistic Regression - l1 penalty - C: 0.005 - Mean Cross Validation Score: 74.75%\n",
      "Logistic Regression - l1 penalty - C: 0.01 - Mean Cross Validation Score: 79.70%\n",
      "Logistic Regression - l1 penalty - C: 0.05 - Mean Cross Validation Score: 80.60%\n",
      "Logistic Regression - l1 penalty - C: 0.1 - Mean Cross Validation Score: 79.50%\n",
      "Logistic Regression - l1 penalty - C: 0.5 - Mean Cross Validation Score: 77.70%\n",
      "Logistic Regression - l1 penalty - C: 1 - Mean Cross Validation Score: 77.70%\n",
      "Logistic Regression - l2 penalty - C: 0.001 - Mean Cross Validation Score: 81.90%\n",
      "Logistic Regression - l2 penalty - C: 0.005 - Mean Cross Validation Score: 79.80%\n",
      "Logistic Regression - l2 penalty - C: 0.01 - Mean Cross Validation Score: 79.05%\n",
      "Logistic Regression - l2 penalty - C: 0.05 - Mean Cross Validation Score: 77.85%\n",
      "Logistic Regression - l2 penalty - C: 0.1 - Mean Cross Validation Score: 77.45%\n",
      "Logistic Regression - l2 penalty - C: 0.5 - Mean Cross Validation Score: 77.05%\n",
      "Logistic Regression - l2 penalty - C: 1 - Mean Cross Validation Score: 77.00%\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regrression\n",
    "for penal in ['l1', 'l2']:\n",
    "    for regu in [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1]:\n",
    "        model = LogisticRegression(penalty = penal, C = regu, random_state = 777)\n",
    "        score = np.mean(cross_val_score(model, X, Y, cv = 5))\n",
    "        print('Logistic Regression - {0} penalty - C: {1} - Mean Cross Validation Score: {2:.2f}%'.format(penal, regu, 100*score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 1024)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
