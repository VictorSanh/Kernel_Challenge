{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kernel Methods challenge\n",
    "\n",
    "Importing base libraries..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "## Debugging requirements\n",
    "import pdb\n",
    "\n",
    "## Performance metrics requirements\n",
    "import time\n",
    "\n",
    "## Kernel SVM requirements\n",
    "from cvxopt import matrix\n",
    "from cvxopt import solvers\n",
    "from scipy.spatial.distance import cdist\n",
    "from numpy.core.defchararray import not_equal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.Loading the data + sanity checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data(dsID, set_type='tr', folder_name='data'):\n",
    "    Xdata_file = folder_name + '/X' + set_type + str(dsID) + '.csv'\n",
    "    X = pd.read_csv(Xdata_file, header=None, names=['Sequence'], dtype={'Sequence': np.unicode_})\n",
    "    if set_type=='tr':\n",
    "        Ydata_file = folder_name + '/Y' + set_type + str(dsID) + '.csv'\n",
    "        Y = pd.read_csv(Ydata_file, index_col=0, dtype={'Bound': np.dtype(bool)})\n",
    "        Y.index = Y.index - 1000*dsID\n",
    "        df = pd.concat([X, Y], axis=1)\n",
    "    else:\n",
    "        df = X\n",
    "    return df\n",
    "\n",
    "## Loading training data\n",
    "tr0 = load_data(0, 'tr')\n",
    "tr1 = load_data(1, 'tr')\n",
    "tr2 = load_data(2, 'tr')\n",
    "\n",
    "## Loading test data\n",
    "te0 = load_data(0, 'te')\n",
    "te1 = load_data(1, 'te')\n",
    "te2 = load_data(2, 'te')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some sanity checks..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Training set 0</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tr0['Bound'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tr0.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tr0.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Training set 1</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tr1['Bound'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tr1.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tr1.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Training set 2</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tr2['Bound'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tr2.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tr2.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Test set 0</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "te0['Sequence'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "te0.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "te0.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Test set 1</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "te1['Sequence'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "te1.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "te1.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Test set 2</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "te2['Sequence'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "te2.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "te2.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First idea: use some distance on the strings as a kernel.\n",
    "However, note that some distances (Hamming) are only defined for sequences of the same size.\n",
    "What is the mininimum and maximum length of the DNA sequences in this first train set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "min_length = tr0['Sequence'].str.len().max(0)\n",
    "max_length = tr0['Sequence'].str.len().max(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('Min sequence length: {}'.format(min_length))\n",
    "print('Max sequence length: {}'.format(max_length))\n",
    "print('Length amplitude: {}'.format(max_length-min_length))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Defining first kernels + running simple classification model\n",
    "\n",
    "### First kernels\n",
    "\n",
    "Ok, so here all sequences have the same length. That means that we can start by something simple like Hamming. However, we may want to use something that would seamlessly extend to DNA sequences of different lengths...\n",
    "Here I will test both the Hamming and the Levenshtein distance as kernels for mapping DNA sequences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Defining both string distances for first kernel tryouts:\n",
    "\n",
    "def hamming_distance(source, target):\n",
    "    \"\"\"Return the Hamming distance between equal-length sequences\"\"\"\n",
    "    if len(source) != len(target):\n",
    "        raise ValueError(\"Undefined for sequences of unequal length\")\n",
    "    return np.count_nonzero(not_equal(source,target))\n",
    "\n",
    "def levenshtein_distance(source, target):\n",
    "    if len(source) < len(target):\n",
    "        return levenshtein(target, source)\n",
    "\n",
    "    # So now we have len(source) >= len(target).\n",
    "    if len(target) == 0:\n",
    "        return len(source)\n",
    "\n",
    "    # We call tuple() to force strings to be used as sequences\n",
    "    # ('c', 'a', 't', 's') - numpy uses them as values by default.\n",
    "    source = np.array(tuple(source))\n",
    "    target = np.array(tuple(target))\n",
    "\n",
    "    # We use a dynamic programming algorithm, but with the\n",
    "    # added optimization that we only need the last two rows\n",
    "    # of the matrix.\n",
    "    previous_row = np.arange(target.size + 1)\n",
    "    for s in source:\n",
    "        # Insertion (target grows longer than source):\n",
    "        current_row = previous_row + 1\n",
    "\n",
    "        # Substitution or matching:\n",
    "        # Target and source items are aligned, and either\n",
    "        # are different (cost of 1), or are the same (cost of 0).\n",
    "        current_row[1:] = np.minimum(\n",
    "                current_row[1:],\n",
    "                np.add(previous_row[:-1], target != s))\n",
    "\n",
    "        # Deletion (target grows shorter than source):\n",
    "        current_row[1:] = np.minimum(\n",
    "                current_row[1:],\n",
    "                current_row[0:-1] + 1)\n",
    "\n",
    "        previous_row = current_row\n",
    "\n",
    "    return previous_row[-1]\n",
    "\n",
    "\n",
    "def build_kernel(arr1, arr2, kernel_fct):\n",
    "    \"\"\"Builds the kernel matrix from numpy array @arr and kernel function @kernel_fct. V1, unnefficient\"\"\"\n",
    "    try:\n",
    "        assert len(arr1) > 0\n",
    "        assert len(arr2) > 0\n",
    "    except AssertionError:\n",
    "        print('At least one of the argument arrays is empty')\n",
    "    if arr1.ndim == 1:\n",
    "        arr1 = arr1.reshape((len(arr1),1))\n",
    "    if arr2.ndim == 1:\n",
    "        arr2 = arr2.reshape((len(arr2),1))\n",
    "    K = cdist(arr1, arr2, lambda u, v: kernel_fct(list(u[0]),list(v[0])))\n",
    "    return K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing kernel computation speed (debugging only):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "Ktr0 = build_kernel(tr0['Sequence'], tr0['Sequence'], kernel_fct = hamming_distance)\n",
    "t1 = time.time()\n",
    "Ktr1 = build_kernel(tr1['Sequence'], tr1['Sequence'], kernel_fct = hamming_distance)\n",
    "t2 = time.time()\n",
    "Ktr2 = build_kernel(tr2['Sequence'], tr2['Sequence'], kernel_fct = hamming_distance)\n",
    "t3 = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('Preparing kernel matrix for a training dataset 1 took {0:d}min {1:d}s with this method'.format(int((t1-t0)/60),int(t1-t0)%60))\n",
    "print('Preparing kernel matrix for a training dataset 2 took {0:d}min {1:d}s with this method'.format(int((t2-t1)/60),int(t2-t1)%60))\n",
    "print('Preparing kernel matrix for a training dataset 3 took {0:d}min {1:d}s with this method'.format(int((t3-t2)/60),int(t3-t2)%60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tools\n",
    "\n",
    "Defining a couple of losses functions that will be useful:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Squared loss\n",
    "def ls_squared(preds, labels):\n",
    "    \"\"\"Returns the hinge loss for preds %labels\"\"\"\n",
    "    try:\n",
    "        assert len(preds) == len(labels)\n",
    "    except AssertionError:\n",
    "        print('preds and labels have different length')\n",
    "    n_samples = len(preds)\n",
    "    return (1.0*np.power(np.linalg.norm(preds-labels),2)) / n_samples\n",
    "\n",
    "## 0/1 loss\n",
    "def ls_binary(preds, labels):\n",
    "    \"\"\"Returns the 0/1 loss for preds %labels\"\"\"\n",
    "    preds = np.sign(preds)\n",
    "    return ls_squared(0.5*preds, 0.5*labels)\n",
    "\n",
    "## Hinge loss\n",
    "def ls_hinge(preds, labels):\n",
    "    \"\"\"Returns the hinge loss for preds %labels\"\"\"\n",
    "    try:\n",
    "        assert len(preds) == len(labels)\n",
    "    except AssertionError:\n",
    "        print('preds and labels have different length')\n",
    "    n_samples = len(preds)\n",
    "    return np.mean(\n",
    "        np.maximum(\n",
    "            np.ones((n_samples,1)) - preds*labels,\n",
    "            np.zeros((n_samples,1))\n",
    "        )\n",
    "    )\n",
    "\n",
    "## Building metrics for reporting on performance\n",
    "class Metric():\n",
    "    def __init__(self, name, measure):\n",
    "        self.name = name\n",
    "        self.measure = measure\n",
    "        \n",
    "m_binary = Metric('Match rate', lambda preds,labels: 1 - ls_binary(preds,labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kernel method parent & kernel SVM\n",
    "\n",
    "Throughout the challenge we will need to use different kernel methods, which will share some attributes and methods. I will thus create an \"abstract\" class kernelMethod:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Kernel methods parent class\n",
    "class kernelMethod():\n",
    "    def __init__(self):\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing I will try out is a kernel SVM method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Implementing a kernel SVM method:\n",
    "class kernelSVM(kernelMethod):\n",
    "    def __init__(self, lbda=0.1, solver='cvxopt'):\n",
    "        self.lbda = lbda\n",
    "        self.solver = solver\n",
    "        self.data = None\n",
    "        self.alpha = None\n",
    "        self.kernel_fct = None\n",
    "    \n",
    "    def format_labels(self, labels):\n",
    "        try:\n",
    "            assert len(np.unique(labels)) == 2\n",
    "        except AssertionError:\n",
    "            print('Error: Labels provided are not binary')\n",
    "        lm,lM = np.min(labels), np.max(labels)\n",
    "        l = (labels==lM).astype(int) - (labels==lm).astype(int)\n",
    "        return l\n",
    "    \n",
    "    def run(self, data, labels, kernel_fct):\n",
    "        \"\"\"Trains the kernel SVM on data and labels\"\"\"\n",
    "        n_samples = labels.shape[0]\n",
    "        # Turning labels into ±1\n",
    "        labels = self.format_labels(labels)\n",
    "        # Binding kernel fct and data as attribute for further predictions\n",
    "        self.kernel_fct = kernel_fct\n",
    "        self.data = data\n",
    "        # Building matrices for solving dual problem\n",
    "        print('Building kernel matrix from {0:d} samples...'.format(n_samples))\n",
    "        tick = time.time()\n",
    "        K = build_kernel(data, data, kernel_fct)\n",
    "        print('...done in {0:.2f}s'.format(time.time()-tick))\n",
    "        d = np.diag(labels)\n",
    "        P = matrix((-1.0/(2*self.lbda))*d*K*d, tc='d')\n",
    "        q = matrix(np.ones((n_samples,1)), tc='d')\n",
    "        G1 = -np.eye(n_samples)\n",
    "        G2 = np.eye(n_samples)\n",
    "        G = matrix(np.vstack((G1,G2)), tc='d')\n",
    "        h1 = np.zeros((n_samples,1))\n",
    "        h2 = (1.0/n_samples)*np.ones((n_samples,1))\n",
    "        h = matrix(np.vstack((h1,h2)), tc='d')\n",
    "        # Construct the QP, invoke solver\n",
    "        sol = solvers.qp(P,q,G,h)\n",
    "        # Extract optimal value and solution\n",
    "        dual = sol['x']\n",
    "        # Solving dual problem via solver\n",
    "        self.alpha = (1.0/(2*self.lbda))*(d @ dual)\n",
    "    \n",
    "    def predict(self, data):\n",
    "        \"\"\"Predict labels for data\"\"\"\n",
    "        try:\n",
    "            assert self.alpha is not None\n",
    "            assert self.kernel_fct is not None\n",
    "        except AssertionError:\n",
    "            print('Error: No successful training recorded')\n",
    "        # Build sv alpha and sv K(x_i(new_data), x_j(ref))\n",
    "        sv_ind = np.nonzero(self.alpha)[0]\n",
    "        sv_alpha = self.alpha[sv_ind]\n",
    "        sv_K = build_kernel(data, self.data[sv_ind], self.kernel_fct)\n",
    "        # Use supvec alpha and supvec K to compute predictions\n",
    "        return sv_K @ sv_alpha\n",
    "    \n",
    "    def assess(self, data, labels, metrics):\n",
    "        \"\"\"Provides the performance of the algorithm on some test data\"\"\"\n",
    "        try:\n",
    "            assert len(data) == len(labels)\n",
    "        except AssertionError:\n",
    "            print('Error: Data and labels have different length')\n",
    "        labels = self.format_labels(labels).reshape((len(labels),1))\n",
    "        preds = self.predict(data)\n",
    "        m = {}\n",
    "        if metrics is not None:\n",
    "            for metric in metrics:\n",
    "                m[metric.name] = metric.measure(preds, labels)\n",
    "        return preds, m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try out our kernel SVM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Method definition\n",
    "lbda = 0.0005\n",
    "kSVM = kernelSVM(lbda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Training SVM + performance assessment on training data\n",
    "kSVM.run(tr0['Sequence'], tr0['Bound'], levenshtein_distance)\n",
    "preds_kSVM_tr0, perf_kSVM_tr0 = kSVM.assess(tr0['Sequence'], tr0['Bound'], metrics=[m_binary])\n",
    "print('Training dataset {0:d}: {1:s}: {2:.1f}%'.format(0, list(perf_kSVM_tr0.keys())[0], 100*list(perf_kSVM_tr0.values())[0]))\n",
    "kSVM_te0_raw = np.sign(kSVM.predict(te0['Sequence'])).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Training SVM + performance assessment on training data\n",
    "kSVM.run(tr1['Sequence'], tr1['Bound'], levenshtein_distance)\n",
    "preds_kSVM_tr1, perf_kSVM_tr1 = kSVM.assess(tr1['Sequence'], tr1['Bound'], metrics=[m_binary])\n",
    "print('Training dataset {0:d}: {1:s}: {2:.1f}%'.format(1, list(perf_kSVM_tr1.keys())[0], 100*list(perf_kSVM_tr1.values())[0]))\n",
    "kSVM_te1_raw = np.sign(kSVM.predict(te1['Sequence'])).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Training SVM + performance assessment on training data\n",
    "kSVM.run(tr2['Sequence'], tr2['Bound'], levenshtein_distance)\n",
    "preds_kSVM_tr2, perf_kSVM_tr2 = kSVM.assess(tr2['Sequence'], tr2['Bound'], metrics=[m_binary])\n",
    "print('Training dataset {0:d}: {1:s}: {2:.1f}%'.format(2, list(perf_kSVM_tr2.keys())[0], 100*list(perf_kSVM_tr2.values())[0]))\n",
    "kSVM_te2_raw = np.sign(kSVM.predict(te2['Sequence'])).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Current performance rate</b>: ??% on training set, ?? on test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Next steps - Results</b>:\n",
    "- What is the reason for such a poor performance rate, even on the training data?\n",
    "- If this is due to Hamming being mostly irrelevant, implement the Levenshtein distance and retry with this new kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Next steps - Computing speed</b>:\n",
    "- Find a way to vectorize the kernel matrix computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def format_preds(preds):\n",
    "    return (0.5*(1+np.sign(preds))).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Predictions on test data\n",
    "kSVM_te0 = pd.DataFrame(\n",
    "    data = format_preds(kSVM_te0_raw),\n",
    "    columns = ['Prediction'])\n",
    "\n",
    "kSVM_te1 = pd.DataFrame(\n",
    "    data = format_preds(kSVM_te1_raw),\n",
    "    columns = ['Prediction'])\n",
    "kSVM_te1.index = kSVM_te1.index + 1000\n",
    "\n",
    "kSVM_te2 = pd.DataFrame(\n",
    "    data = format_preds(kSVM_te2_raw),\n",
    "    columns = ['Prediction'])\n",
    "kSVM_te2.index = kSVM_te2.index + 2000\n",
    "\n",
    "frames = [kSVM_te0, kSVM_te1, kSVM_te2]\n",
    "kSVM_te = pd.concat(frames)\n",
    "kSVM_te.index.rename('ID')\n",
    "\n",
    "kSVM_te.to_csv('predictions/kSVM_te.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
